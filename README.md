# AI-ML-Journey
My 6-month journey to become an AI/ML Engineer.

I am a 2nd-year engineering student building projects daily to gain strong practical skills in machine learning and AI systems.

---

## Learning Roadmap

### Day 1
- Python basics
- Variables, lists, loops, functions
- Mini student analysis project

### Day 2
- Introduction to Machine Learning
- Linear Regression model
- Predicted student scores

### Day 3
- Logistic Regression
- First classification model
- Pass/fail prediction

### Day 4
- Titanic survival prediction
- Data cleaning
- Logistic regression
- ~75% accuracy

### Day 5
- Spam detection using Logistic Regression
- Text preprocessing with CountVectorizer
- Learned precision, recall, F1-score
- Confusion matrix analysis
- Tested custom messages
- Understood how text converts into numerical vectors

### Day 6
- Linear Regression model
- House price prediction
- Features: area, bedrooms, bathrooms
- Learned coefficients and intercept
- Evaluated using MAE and MSE
- Added user input for real-time prediction

### Day 7
- Decision Tree classifier
- Loan approval prediction
- Learned gini, samples, value, class
- Visualized decision tree
- Built Streamlit web app
- Real-time loan approval prediction

### Day 8
- Used real-world loan dataset (CSV)
- Data cleaning (handled missing values)
- Selected important numeric features
- Compared Logistic Regression and Decision Tree
- Achieved ~81% accuracy
- Learned about model evaluation and tuning basics

### Day 9
-Implemented K-Nearest Neighbors (KNN) algorithm
-Understood distance-based learning (Euclidean distance)
-Learned how KNN makes predictions using nearest neighbors
-Explored effect of different K values
-Understood overfitting (K=1) and underfitting (large K)
-Built a basic classification model using KNN
-Compared KNN with previous models

### Day 10
-Learned feature scaling using StandardScaler
-Understood why scaling is important for distance-based algorithms
-Applied scaling on dataset before training KNN
-Visualized KNN decision boundary (2D intuition)
-Understood how KNN forms non-linear decision regions
-Explored impact of K on decision boundary shape
-Improved model performance using proper preprocessing

### Day 11
-Learned Data Visualization for Exploratory Data Analysis (EDA)
-Used Matplotlib and Seaborn for plotting
-Created Histogram to understand feature distribution
-Used Boxplot to detect outliers
-Used Countplot to analyze class distribution
-Generated Heatmap to study feature correlations
-Created Pairplot to visualize relationships between features
-Gained insights into data patterns, balance, and feature importance[count plot](image.png)
[histogram](image-1.png)
[boxplot](image-2.png)
[heatmap](image-3.png)
[pairplot](image-4.png)